# üß† Medical Risk MLOps ‚Äî Stroke Risk Prediction

An end-to-end **stroke risk prediction** system built with CatBoost + MLflow + FastAPI + Streamlit.

---

## üìã Table of Contents

- [Project Structure](#-project-structure)
- [Architecture & Design Decisions](#-architecture--design-decisions)
- [Installation](#-installation)
- [Getting Started](#-getting-started)
- [Running with Docker](#-running-with-docker)
- [Deploy to Streamlit Cloud](#-deploy-to-streamlit-cloud)
- [API Usage](#-api-usage)
- [Tech Stack](#-tech-stack)
- [Model Performance](#-model-performance)

---

## üóÇ Project Structure

```
medical-risk-mlops/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/stroke_data.csv          # Kaggle Stroke Prediction dataset (5,110 records)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model.cbm                    # Standalone CatBoost model (for Docker/Cloud)
‚îÇ   ‚îî‚îÄ‚îÄ metadata.json                # Optimal threshold & model metadata
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # Central configuration: paths, hyperparams, features
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_data.py             # CSV loader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate.py              # Data validation (missing values, dtype checks)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py            # Cleaning, BMI imputation, train/test split
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Model training + MLflow logging + SHAP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py              # Metrics + threshold tuning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py               # Model loading + inference
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ schema.py                # Pydantic input/output schemas
‚îÇ       ‚îî‚îÄ‚îÄ main.py                  # FastAPI endpoints (/predict, /explain, /health)
‚îÇ
‚îú‚îÄ‚îÄ .streamlit/config.toml           # Streamlit theme & server settings
‚îú‚îÄ‚îÄ streamlit_app.py                 # üñ• Streamlit dashboard (visual interface)
‚îú‚îÄ‚îÄ Dockerfile                       # Multi-stage Docker container
‚îú‚îÄ‚îÄ docker-compose.yml               # 3 services: API + Streamlit + MLflow UI
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îî‚îÄ‚îÄ README.md                        # This file
```

---

## üéØ Architecture & Design Decisions

### 1. `config.py` ‚Äî Central Configuration

**Why:** All hyperparameters, file paths, and feature names are stored in one place. Need to change something? Edit a single file.

### 2. `load_data.py` ‚Üí `validate.py` ‚Üí `preprocess.py` ‚Äî Data Pipeline

**Why:** Separating data loading ‚Üí validation ‚Üí cleaning into distinct modules makes each independently testable and replaceable.

| Step            | What It Does                                                                                 |
| --------------- | -------------------------------------------------------------------------------------------- |
| `load_data.py`  | Reads the raw CSV file                                                                       |
| `validate.py`   | Checks for missing values, target distribution, and dtype consistency                        |
| `preprocess.py` | Drops the `id` column, imputes missing BMI with median, performs stratified train/test split |

### 3. `train.py` ‚Äî Model Training + MLflow

**Why:** Trains a CatBoost model and records everything to MLflow for reproducibility.

**What gets logged:**

- Hyperparameters (iterations, depth, learning_rate, class_weights)
- Metrics: ROC-AUC, Precision, Recall, F1, optimal threshold
- Artifacts: confusion matrix (PNG + JSON), classification report (TXT), SHAP summary plot (PNG)
- The model itself ‚Üí registered in MLflow Model Registry
- Standalone export ‚Üí `models/model.cbm` + `models/metadata.json` (for Docker/Cloud)

### 4. `evaluate.py` ‚Äî Threshold Tuning

**Why:** The dataset is highly imbalanced (**95% no-stroke** vs **5% stroke**). The default 0.5 threshold misses too many stroke cases. We use **F2-score** to find the optimal threshold (‚âà0.69), which weighs recall more heavily.

### 5. `predict.py` ‚Äî Model Loading & Inference

**Why:** Loads the model from the MLflow Registry and runs predictions for a single patient. Used by both the API and Streamlit.

### 6. `schema.py` ‚Äî Pydantic Schemas

**Why:** Guarantees correct input data types for the API. Invalid types or missing fields return clear error messages.

### 7. `api/main.py` ‚Äî FastAPI REST API

**Why:** Serves the model as an HTTP service. Any application (web, mobile, microservice) can call this API for predictions.

| Endpoint   | Method | Description                                 |
| ---------- | ------ | ------------------------------------------- |
| `/health`  | GET    | Health check & system status                |
| `/predict` | POST   | Stroke risk prediction for a single patient |
| `/explain` | POST   | SHAP-based prediction explanation           |

### 8. `streamlit_app.py` ‚Äî Dashboard Interface

**Why:** A visual interface for non-technical users. Fill in patient info ‚Üí get predictions ‚Üí see which factors drive the risk via SHAP visualization.

### 9. Dual-Mode Model Loading

**Why:** After training, the model is saved in two locations:

1. **MLflow Registry** ‚Üí for local development (alongside experiment tracking)
2. **`models/model.cbm`** ‚Üí for Docker and Cloud deployment (no MLflow dependency)

Both the API and Streamlit check for the `.cbm` file first ‚Üí fall back to MLflow if not found.

### 10. Class Imbalance Handling

**Why:** 4,861 no-stroke vs 249 stroke samples. We use `class_weights=[1, 20]` to tell CatBoost to treat stroke cases as 20x more important during training.

---

## ‚öôÔ∏è Installation

```bash
# 1. Create a virtual environment
python -m venv .venv

# 2. Activate it
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Linux/Mac

# 3. Install dependencies
pip install -r requirements.txt
```

---

## üöÄ Getting Started

### Step 1 ‚Äî Train the Model

```bash
python -m src.models.train
```

**What happens:**

- Data is loaded and preprocessed
- CatBoost model is trained (500 iterations)
- Threshold is optimized for recall
- SHAP summary plot is generated
- Everything is logged to MLflow
- Model is registered in MLflow Registry
- `models/model.cbm` and `models/metadata.json` are exported

**Output:** `ROC-AUC: ~0.85 | Recall: ~0.74 | Threshold: ~0.69`

### Step 2a ‚Äî Streamlit Dashboard (Recommended)

```bash
streamlit run streamlit_app.py --server.port 8890
```

Open **http://localhost:8890** in your browser.

> ‚ö†Ô∏è **Windows Hyper-V Note:** Port 8501 (default) may be blocked by Hyper-V. Use `--server.port 8890` to run on a different port.

### Step 2b ‚Äî FastAPI API (Alternative)

```bash
uvicorn src.api.main:app --port 8000
```

API docs: **http://localhost:8000/docs** (Swagger UI)

### Step 3 ‚Äî MLflow UI (Optional)

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

**http://localhost:5000** ‚Üí Visually explore all experiments, metrics, and artifacts.

---

## üê≥ Running with Docker

### Single Service

```bash
# Build the image
docker build -t stroke-risk-mlops .

# Run FastAPI
docker run -p 8000:8000 stroke-risk-mlops uvicorn src.api.main:app --host 0.0.0.0 --port 8000

# Run Streamlit
docker run -p 8501:8501 stroke-risk-mlops streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
```

### Docker Compose (All 3 Services)

```bash
docker-compose up -d
```

| Service       | URL                   | Description            |
| ------------- | --------------------- | ---------------------- |
| **API**       | http://localhost:8000 | FastAPI REST endpoint  |
| **Streamlit** | http://localhost:8501 | Dashboard interface    |
| **MLflow**    | http://localhost:5000 | Experiment tracking UI |

```bash
# Stop
docker-compose down
```

> **Note:** Docker containers use the standalone `models/model.cbm` file (no MLflow registry dependency). This means a model trained on Windows runs seamlessly inside a Linux container.

---

## ‚òÅÔ∏è Deploy to Streamlit Cloud

1. Push the project to **GitHub**
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Select your GitHub repo ‚Üí choose `streamlit_app.py`
4. Click **Deploy**

> **Important:** Make sure `models/model.cbm` and `models/metadata.json` are in the repo (not in `.gitignore`).

---

## üì° API Usage

### Prediction Request

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "Male",
    "age": 67,
    "hypertension": 0,
    "heart_disease": 1,
    "ever_married": "Yes",
    "work_type": "Private",
    "Residence_type": "Urban",
    "avg_glucose_level": 228.69,
    "bmi": 36.6,
    "smoking_status": "formerly smoked"
  }'
```

### Response

```json
{
  "prediction": 1,
  "probability_stroke": 0.8357
}
```

---

## üõ† Tech Stack

| Technology       | Purpose                                                   |
| ---------------- | --------------------------------------------------------- |
| **CatBoost**     | Gradient boosting with native categorical feature support |
| **MLflow**       | Experiment tracking, model registry, artifact storage     |
| **FastAPI**      | High-performance REST API with auto-generated docs        |
| **Streamlit**    | Interactive dashboard interface                           |
| **SHAP**         | Model explainability (which features drive predictions)   |
| **Pydantic**     | Input/output data validation for the API                  |
| **Docker**       | Portable containerized deployment                         |
| **scikit-learn** | Train/test split, metric computation                      |

---

## üìä Model Performance

| Metric        | Value      |
| ------------- | ---------- |
| ROC-AUC       | **0.8485** |
| Recall        | **0.7400** |
| Threshold     | **0.6904** |
| Class Weights | [1, 20]    |

---

_Built with ‚ù§Ô∏è using CatBoost + MLflow + FastAPI + Streamlit_
